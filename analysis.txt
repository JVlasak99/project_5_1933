This is the analysis of each hash function I created on each example .txt file provided.


HASH1
		Cant	Getty	Key	Prov	That
Avg Collision	2	2	1	3	3
Longest Chain	14	12	4	16	16
Unique		245	195	50	307	289
Empty		65	82	115	68	63
Non-empty	84	67	34	81	86


HASH2
		Cant	Getty	Key	Prov	That
Avg Collision	2	2	1	2	2
Longest Chain	8	5	3	9	10
Unique		249	191	50	324	295
Empty		56	56	112	35	47
Non-empty	93	93	37	114	102


HASH3
		Cant	Getty	Key	Prov	That
Avg Collision	2	1	1	2	2
Longest Chain	6	5	3	9	8
Unique		247	198	50	320	297
Empty		40	48	112	31	29
Non-empty	109	101	37	118	120


As you can see, there is pretty consistent "bettering" of the statistics as we go from hash1 to hash3. Using hash3, the average collision for all of the .txt files are between 1 and 2, and the longest chains are all below 10. There is a consistent drop of the number of empty buckets, which is a good sign since it means more buckets are being filled (less collisions). 
